{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras LSTM model",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unclepeddy/tf-serving-fun/blob/master/examples/keras-lstm-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-IqaNHIgtdCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jo-RrRODt9bo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specify hyperparams\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "lstm_width = 32\n",
        "embedding_dim = 32\n",
        "epochs = 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_pNZDObt9jP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build and compile a simple LSTM model\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.imdb.load_data(num_words=max_features)\n",
        "\n",
        "train_data = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "  train_data, maxlen=maxlen)\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "  test_data, maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_features, embedding_dim))\n",
        "model.add(tf.keras.layers.LSTM(lstm_width))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TE1lyk4ut9pf",
        "colab_type": "code",
        "outputId": "e31db08a-5832-4812-ac45-ef7c29812b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# Train model using a slice of training data\n",
        "train_data = train_data[:100]\n",
        "train_labels = train_labels[:100]\n",
        "\n",
        "history = model.fit(train_data, train_labels, \n",
        "\tepochs = 1,\n",
        "\tbatch_size=batch_size,\n",
        "\tvalidation_split=0.2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "80/80 [==============================] - 2s 22ms/sample - loss: 0.6959 - acc: 0.3875 - val_loss: 0.6934 - val_acc: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aHNKNus-uLXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Export model\n",
        "\n",
        "import os \n",
        "model_name = 'lstm_model'\n",
        "model_base_path = os.path.join(os.getcwd(), model_name)\n",
        "model_version = 0\n",
        "model_version_path = os.path.join(model_base_path, str(model_version))\n",
        "\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"MODEL_DIR\"] = os.path.abspath(model_base_path)\n",
        "os.environ[\"MODEL_VERSION_DIR\"] = os.path.abspath(model_version_path)\n",
        "\n",
        "!rm -rf $MODEL_DIR\n",
        "\n",
        "# Enable to strip default op attributes\n",
        "enable_forward_compat = True\n",
        "\n",
        "if (enable_forward_compat):\n",
        "\n",
        "  prediction_signature = tf.saved_model.signature_def_utils.build_signature_def(\n",
        "    inputs={'input': tf.saved_model.build_tensor_info(model.input)},\n",
        "    outputs={t.name: tf.saved_model.build_tensor_info(t) for t in model.outputs},\n",
        "    method_name= tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
        "  )\n",
        "\n",
        "  builder = tf.saved_model.Builder(model_version_path)\n",
        "  builder.add_meta_graph_and_variables(\n",
        "    tf.keras.backend.get_session(),\n",
        "    [tf.saved_model.tag_constants.SERVING],\n",
        "    signature_def_map = {\n",
        "      tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature\n",
        "    },\n",
        "    strip_default_attrs=True\n",
        "  )\n",
        "\n",
        "  builder.save()\n",
        "\n",
        "else:\n",
        "  tf.saved_model.simple_save(\n",
        "    tf.keras.backend.get_session(),\n",
        "    model_version_path, \n",
        "    inputs={'input': model.input},\n",
        "    outputs={t.name:t for t in model.outputs}\n",
        "  )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ui3pBVW4mBQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Explore the model signature\n",
        "!saved_model_cli show --dir $MODEL_VERSION_DIR --all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9_EsqTkkhohv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "!apt-get install tensorflow-model-server\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPqJCxbwi2i-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=\"$MODEL_NAME\" \\\n",
        "  --model_base_path=\"$MODEL_DIR\" >server.log 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6X8myepjLL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cat server.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mGNG4lAVlaWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "0a3937bb-fccf-43c1-9c80-6b77287e7fdb"
      },
      "cell_type": "code",
      "source": [
        "# Query your model's status\n",
        "!curl http://localhost:8501/v1/models/$MODEL_NAME"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            " \"model_version_status\": [\n",
            "  {\n",
            "   \"version\": \"0\",\n",
            "   \"state\": \"AVAILABLE\",\n",
            "   \"status\": {\n",
            "    \"error_code\": \"OK\",\n",
            "    \"error_message\": \"\"\n",
            "   }\n",
            "  }\n",
            " ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I0EGNEFbpZD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83fe7988-e8ea-4e7c-cfd5-e66bb092fd45"
      },
      "cell_type": "code",
      "source": [
        "# Query the model\n",
        "! pip install -q requests\n",
        "import json, requests\n",
        "\n",
        "samples = test_data[0:2].tolist()\n",
        "request_data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": samples})\n",
        "headers = {\"content-type\" : \"application/json\"}\n",
        "server_url = \"http://localhost:8501/v1/models/{}:predict\".format(model_name) \n",
        "\n",
        "json_response = requests.post(server_url, data=request_data, headers=headers)\n",
        "pred = json.loads(json_response.text)['predictions']\n",
        "\n",
        "print(pred)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.498789], [0.500337]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
